---
title: "Predicting MSRP based on Car Features"
author: "Leslie Cervantes Rivera"
date: "2024-10-26"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


![image](~/Desktop/price_car.jpg)


(https://stock.adobe.com/search?k=car+price+tag)

# Introduction

The purpose of this project is to build a machine learning model to predict the Manufacturer’s Suggested Retail Price (MSRP) of cars based on various features such as make, year, and engine fuel type. By examining these features, I aim to identify the most significant factors that contribute to the price variations across models. Additionally, I will investigate whether there is a significant price difference among many transmission types such as automated manual, automatic, direct drive, and manual. This analysis will provide insights into the potential effects of transmission type on overall cost. 

![image](~/Desktop/MSRP1.pdf){width=30%}

(https://www.cars.com/articles/what-does-msrp-mean-1420690419467/)

## Why MSRP?

As an adult, I believe it is important to understand how a car’s features affect its MSRP. MSRP serves as the price the original producer of the car suggests the cost to be (https://www.indeed.com/career-advice/career-development/msrp).The main purpose of MSRP is to give distributors and retailers guidelines to maintain prices consistent and affordable for the majority of customers across locations. This also serves as the starting point for negotiations at the dealership.

MSRP not only sets expectations around affordability, financing and loan terms, but it also affects recurring expenses like insurance. In today’s economy, MSRP has been affected by inflation, supply chain disruptions, and technological advancements. Understanding these factors is crucial for making wise financial decisions, especially for new buyers who want to get the best value for their investment. This project will shed light on the factors that influence MSRP in the automotive market. 

## Data
The data that will be used for this project comes from Kaggle, a platform for everyone to compete, collaborate, and learn, and was provided from user Rupinder Singh Rana. The dataset provides different features of cars along with the price from 1990 to 2017 (https://www.kaggle.com/datasets/rupindersinghrana/car-features-and-prices-dataset). The dataset includes variables such as `Make`, `Model`, `Year`, `Transmission.Type`, `MSRP`, & etc and approximately eleven thousand observations. 

# Explanatory Data Analysis 

In this section I am conducting Explanatory Data Analysis (EDA) to better understand the data and the variables that may influence the `MSRP` of cars. This is the stage where we are given insights into the structure and characteristics of the data, for instance missing values and outliers. 

I will provide visuals on missing values, correlation matrices, and boxplots to give us an idea of what the data is providing. 

## Loading Data 

Firstly, I am going to load the dataset.
```{r}
library(dplyr)
car_data <- read.csv("~/Desktop/data.csv")
car_data <- car_data %>% 
  mutate(Category = ifelse(Make %in% c("BMW", "Audi", "Mercedes-Benz", "Volvo", "Ferrari", 
          "Alfa Romero", "McLaren", "Maybach","Porsche", "Saab", "Cadillac", "Bentley", "Lamborghini", 
          "Lincoln", "Rolls-Royce", "Buick", "Maserati","Lexus", "Aston Martin", "Land Rover",
          "Lotus", "Infiniti", "Genesis", "Bugatti"),
                         "Luxury",
                         "Non-Luxury"))

head(car_data)
```

Now, I am going to get the dataset's dimensions. This tells us the number of rows and columns.
```{r}
dim(car_data)
```

This dataset includes 11,914 rows and 17 columns. The 11,914 rows are different cars and 16 columns are the car's features and the remaining one is the `MSRP`. Here are the car's features and price:

- `Make`: The company that produces the vehicle

- `Model`: The product name of the vehicle used by the manufacturer

- `Year`: The year the vehicle was made 

- `Engine.Fuel.Type`: The type of fuel the vehicle uses

- `Engine.HP`: The engine's horse power

- `Engine.Cylinders`: Number of cylinders

- `Transmission.Type`: The type of transmission the vehicle has

- `Driven_Wheels`: The type of wheels the vehicle has

- `Number.of.Doors`: The number of doors the vehicle has

- `Market.Category`: The classification of the vehicle 

- `Vehicle.Size`: The size of the vehicle

- `Vehicle.Style`: Type of vehicle

- `highway.MPG`: How many miles a vehicle can travel on a gallon of gas while driving on the freeway

- `city.MPG`: How many miles a vehicle can travel on a gallon of gas while driving in the city

- `Popularity`: Popularity of the vehicle

- `MSRP`: Price of the vehicle in ($)

- `Category`: Whether a a car is luxury or non-luxury

After finding out how many observations we have, we want to know how much missing data there is. It is important to know how much data we are missing as it can lead to a reduced sample size, biased results, or misleading results. 

## Tidying Data 

### Missing Data

```{r}
missing <- is.na(car_data)

total_missing <- sum(missing)
print(total_missing)
```

The dataset is missing 105 observations. Let us see the percentage by variable. 

```{r}
library(naniar)
vis_miss(car_data)

colSums(is.na(car_data))
```

Looking at the graph, we can see there are a few missing observations for `Engine.HP`, `Engine.Cylinders`, `Number.of.Doors`. Specifically, there are 69 missing observations for `Engine.HP`, 30 for `Engine.Cylinders`, and 6 for `Number.of.Doors`. While skimming through the dataset, I noticed the function viss_miss did not catch other missing values due how it was represented. 

```{r}
library(tidyr)

updated_car_data <- car_data %>% 
  drop_na(Engine.HP, Engine.Cylinders, Number.of.Doors) 

NA_car_data <- subset(updated_car_data, !( Engine.Fuel.Type == "" | Engine.Cylinders == 0 
                                           | Transmission.Type == "UNKNOWN"))
```

Upon reviewing the dataset, I decided on removing the observations with missing data in `Engine.HP`, `Engine.Cylinders`, or `Number.of.Doors` since we could afford to remove the missing observations. After reviewing the updated set with the missing values removed, I noticed that some rows had a value of 0 in `Engine.Cylinders` which seemed incorrect. As a result, I chose to remove the rows.  

In the `Market.Category` variable there are three thousand observations marked as "N/A" that the program did not detect. To evaluate the significance of the missing data points, I conducted two trials: one where missing observations were removed (No NA trial) and the other where missing observations were kept without imputation (NA trial). 

After training and comparing the model results on both trials, the NA trial demonstrated better performance across RMSE and $R^2$. This tell us that retaining the missing values contributes to the predictive power of the models. I chose not to impute the missing data points because it will introduce bias which would lead to false conclusions and be misleading. 

## Outliers

To better understand the data, we're going to visualize predictors with a wide range of values. This is important as they create outliers in the data. Outliers are data values that significantly deviate from the majority of other values. 

```{r}
ggplot(NA_car_data, aes(MSRP)) +
  geom_boxplot() + coord_flip() + labs(x = "MSRP (in thousands)")
ggplot(NA_car_data, aes(highway.MPG)) +
  geom_boxplot() + coord_flip() + labs(x = "Highway MPG")
ggplot(NA_car_data, aes(Engine.HP)) +
  geom_boxplot() + coord_flip() + labs(x = "Engine Horse Power")

```

As you can see the `MSRP` boxplot reveals significant outliers, with values ranging from approximately \$250,000 to \$2,000,000 (in thousands). In the `highway.MPG` variable, there is a single extreme outlier approximately 350 MPG, which is unrealistic. Lastly, `Engine.HP` has outliers ranging from 500 to 1,000 horse power. 

Let's transform the data to exclude the extreme outliers.
```{r}
IQR_HP_NA <- IQR(updated_car_data$Engine.HP)
lower_HP_NA <- quantile(updated_car_data$Engine.HP, 0.25) - 2.0 * IQR_HP_NA
upper_HP_NA <- quantile(updated_car_data$Engine.HP, 0.75) + 2.5 * IQR_HP_NA

IQR_highway_NA <- IQR(updated_car_data$highway.MPG)
lower_highway_NA <- quantile(updated_car_data$highway.MPG, 0.25) - 3.0 * IQR_highway_NA
upper_highway_NA <- quantile(updated_car_data$highway.MPG, 0.75) + 4.0 * IQR_highway_NA

IQR_MSRP_NA <- IQR(updated_car_data$MSRP)
lower_MSRP_NA <- quantile(updated_car_data$MSRP, 0.25) - 3.0 * IQR_MSRP_NA
upper_MSRP_NA <- quantile(updated_car_data$MSRP, 0.75) + 2.0 * IQR_MSRP_NA

outliers_removed_car_NA <- NA_car_data %>% 
  filter(Engine.HP >= lower_HP_NA & Engine.HP <= upper_HP_NA) %>% 
  filter(highway.MPG >= lower_highway_NA & highway.MPG <= upper_highway_NA) %>% 
  filter(MSRP >= lower_MSRP_NA & MSRP <= upper_MSRP_NA)
```


```{r}
library(ggplot2)

ggplot(outliers_removed_car_NA, aes(MSRP)) +
  geom_boxplot() + coord_flip() + labs(x = "MSRP (in thousands)")
ggplot(outliers_removed_car_NA, aes(highway.MPG)) +
  geom_boxplot() + coord_flip() + labs(x = "Highway MPG")
ggplot(outliers_removed_car_NA, aes(Engine.HP)) +
  geom_boxplot() + coord_flip() + labs(x = "Engine Horse Power")
```

Above are the same boxplots after applying the transformations to the data. Some outliers remain which are intentionally retain to preserve the high range of values. 

## Transformation

```{r}
converted_car_data_NA <- outliers_removed_car_NA %>% 
    mutate(
        Market.Category = fct_other(Market.Category, 
            keep = c("Performance", "Hatchback", "Crossover"), 
            other_level = "Other"),
        Vehicle.Style = fct_lump(Vehicle.Style, n = 11, other_level = "Other"),
        Make = fct_lump(Make, n = 32, other_level = "Other"),
        MSRP = MSRP / 1000,
        Vehicle.Size = factor(Vehicle.Size),
        Vehicle.Style = factor(Vehicle.Style),
        Engine.Fuel.Type = factor(Engine.Fuel.Type),
        Driven_Wheels = factor(Driven_Wheels),
        Transmission.Type = factor(Transmission.Type),
        Make = factor(Make),
        Model = factor(Model),
        Category = factor(Category)
    )
```



## Visual Data

We will explore some relationships between the predictors and MSRP.

### MSRP vs Transmission Type 

```{r}
library(dplyr)
library(ggplot2)

#updated_car_data <- updated_car_data %>% 
  #mutate(Transmission.Type = factor(Transmission.Type),
         #Category = factor(Category))

ggplot(converted_car_data_NA, aes(x = Transmission.Type, y = MSRP)) + 
  geom_boxplot(fill = "slateblue", alpha = 0.2) + xlab("Transmission Type") + 
  ylab("MSRP (in thousands)") + ylim(0,75)

```

The boxplot visualizes the distribution of `MSRP` across different `Transmission.Type` categories.The median MSRP varies among transmission types, with "AUTOMATIC" and "AUTOMATED_MANUAL" having equal highest median. The interquartile range (IQR), which is the spread of the data, reveals that "DIRECT_DRIVE" has the narrowest price range, indicating consistency in pricing for this transmission type.

Examining the whiskers,"MANUAL" has a longer spread toward the maximum, while "AUTOMATIC" displays an equal amount of spread toward the maximum and minimum values. Additionally, three out of the four transmissions have a good amount of outliers, highlighting the presence of cars with MSRP significantly above or below their boxplots.  

### MSRP vs Make

```{r}
common_10 <- converted_car_data_NA %>% 
  filter(Make == c("BMW", "Mercedes-Benz", "Lincoln", "Lexus", "Infiniti", "Honda", "Toyota", 
                   "Nissan", "Ford", "Subaru"))
ggplot(common_10, aes(x = Make, y = MSRP)) +
  geom_boxplot(fill = "purple") + xlab("Car Make") + ylab("MSRP (in thousands)")
```

The boxplots compare the `MSRP` distributions for five luxury and five non-luxury car `Make`s. As we can see, Mercedes-Benz has a greater IQR than the other car makes.  
- Mercedes-Benz: The median `MSRP` is approximately \$42,000, with an IQR ranging from around \$5,000 and \$55,000. 
- Toyota: The median `MSRP` is around \$30,000, with an IQR ranging from around \$23,000 and \$34,000 with an outlier around \$64,000. 

### MSRP vs Category
```{r}
ggplot(converted_car_data_NA, aes(x = Category, y = MSRP)) +
  geom_boxplot(fill = "coral") + ylim(0, 90) + ylab("MSRP (in thousands)")
```

The boxplots compare the distribution of `MSRP` to `Category`. This shows the distribution within luxury and non-luxury. 

- Luxury: The median `MSRP` is approximately \$40,000, with an IQR range from around \$35,000 to \$52,000. The minimum `MSRP` is about $10,000 and maximum (excluding outliers) is around \$82,000. There are various amounts of outliers ranging from approximately \$83,000 to \$86,000. 

- Non-luxury: The median `MSRP` is approximately \$26,000, with an IQR from around \$18,000 to \$33,000. The minimum `MSRP` is about \$3,000 and maximum (excluding outliers) is around \$52,000. There are various amounts of outliers ranging from about \$53,000 to \$85,000. 

### MSRP vs Year

```{r}
ggplot(converted_car_data_NA, aes(x = factor(Year), y = MSRP)) +
  geom_point(alpha = 0.7, color = "darkgreen")  +
  labs( x = "Year", y = "MSRP (in thousands)") + ylim(0,200)
```

Looking at the scatterplot of the distribution of `MSRP` and `Year`, we see an upward trend in the `MSRP` values over the years. After the year 2000, the prices dramatically increased suggesting vehicle prices increase every year. The significant increase could indicate factors such economic changes, advancements in technology, inflation, or an increase in demand.

### Correlation Matrix 

```{r}
library(corrplot)
converted_car_data_NA %>% 
  select(where(is.numeric)) %>% 
  cor() %>% 
  corrplot(addCoef.col = 1, , number.cex = 0.6)
  
```

Now, we are going to explore the relationships between pairs of variables in the dataset. As a reminder, correlation coefficients range from -1 to 1, where values close to -1 or 1 indicating a stronger relationship. 

- City MPG and Highway MPG: A very strong positive correlation (r = 0.91) shows that cars with better fuel efficiency in city conditions will also be efficient in highway conditions
- Engine Cylinders and Engine HP: There is a strong positive correlation (r = 0.71), indicating vehicles with more engine cylinders tend to have higher horsepower.
- Engine Horsepower and MSRP: The strong positive correlation (r = 0.75) indicates vehicles with higher horsepower tend to have higher prices. 
- Engine Cylinders and Fuel Efficiency: There is a strong negative correlation between engine cylinders and both city mpg (r = -0.68) and highway mpg 
(r = -0.70). This implies vehicles with more cylinders tend to have worse fuel efficiency in both city and highway conditions.
- Engine Horsepower and Fuel Efficiency: There is moderate negative correlation between engine horsepower and both city mpg (r = -0.49) and highway mpg
(r = -0.44). This implies vehicles with more horsepower results in lower fuel efficiency.

# Setting up Models 

It is time to set up our models. This is where split our data and fit the training data into different models to see which one is the best to predict the `MSRP`. Before fitting, we have to create the recipe and the folds for k-fold cross validation.

## Data Split

The first step would be to split the data into training and testing data sets. The training data is used to train the program by allowing it to see the response of 70% of the data and the remaining unseen 30% to the testing data. I chose these proportions to allow the data to learn and to avoid over-fitting. This is important as it will help the program create a more accurate test result. The split is stratified on the `MSRP` and I set the random seed to keep working with the same data throughout the models.

```{r}
set.seed(314)

NA_car_split <- initial_split(converted_car_data_NA, prop = 0.7, 
                           strata = MSRP)
NA_car_training <- training(NA_car_split)
NA_car_testing <- testing(NA_car_split)

```

To make sure the data is split evenly, we need to check the dimensions.

```{r}
dim(NA_car_training)
dim(NA_car_testing)
```

The observations for the training and testing data sets are adequate. 

### K-Fold Cross Validation 
```{r}
NA_car_folds <- vfold_cv(NA_car_training, v = 5, strata = MSRP)
```

